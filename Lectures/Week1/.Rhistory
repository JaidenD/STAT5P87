# Find the current working directory
getwd()
# Once working directory is set
# load data using read.csv()
mydata = read.csv('simple-classification-data.csv')
mydata
# load the dataset
mydata = read.csv('prostate-data.csv')
### STAT5P87 - Week 2
getwd()
# Once working directory is set
# load data using read.csv()
mydata = read.csv('simple-classification-data.csv')
# mydata is a "data.frame"
# look at the header of the data (first 6 rows)
head(mydata)
# Grab a specific column by name
mydata$x1
# To get the third row, second column (0.9993)
mydata[3,2]
# Grab all of column 2
mydata[,2]
# Grab all of row 3
mydata[3,]
# Get the type of each column
str(mydata)
# Get the type of each column
str(mydata)
# Create a `vector' or ordered set
# c() for `concatenate'
c(1, 2)
c(1, 5)
# The c() function can go into indexing
# our dataframe. For example, rows 2, 3, 4
# all columns
mydata[c(2, 3, 4),]
# Create matrices from the dataframe
# Not necessary, but good practice to always
# specify the columns and rows
y = matrix(mydata$y, ncol = 1, nrow = 200)
# Can make the matrix explicitly
X = matrix(c(mydata$x1, mydata$x2), ncol = 2, nrow = 200)
X
# Or use the model.matrix() function
X = model.matrix(y ~ x1 + x2, data=mydata)
X
x1
mydata$x1
# Settings to customize your plot
plot(mydata$x1, mydata$x2,
xlab = 'x1', ylab = 'x2',
main = 'Scatterplot of x1 vs. x2',
lwd = 2, cex = 1, cex.lab = 1.5,
cex.axis = 1.5, bty = 'n',
col = 'black')
# to select only the y = 0 values
mydata$x1[mydata$y == 0]
plot(mydata$x1[mydata$y == 0], mydata$x2[mydata$y == 0],
xlab = 'x1', ylab = 'x2',
main = 'Scatterplot of x1 vs. x2',
lwd = 2, cex = 1, cex.lab = 1.5,
cex.axis = 1.5, bty = 'n',
col = 'dodgerblue3',
xlim = c(min(mydata$x1), max(mydata$x1)),
ylim = c(min(mydata$x2), max(mydata$x2)))
# plot() creates a new figure
# use points() or lines() to add to an existing figure
points(mydata$x1[mydata$y == 1], mydata$x2[mydata$y == 1],
lwd = 2, cex = 1, col = 'darkorange2')
# Compute median x1 value for y = 0 and  y = 1 observations
median_blue = median(mydata$x1[mydata$y == 0])
median_orange = median(mydata$x1[mydata$y == 1])
# Add x1 median lines to plot
lines(c(median_blue, median_blue), c(-5, 5),
col = 'dodgerblue3', lwd = 2)
lines(c(median_orange, median_orange), c(-5, 5),
col = 'darkorange2', lwd = 2)
# Define a threshold as a classification rule
# the midpoint between the two medians
threshold = (median_blue + median_orange) / 2
# Add threshold to plot
lines(c(threshold, threshold), c(-5, 5),
col = 'black', lwd = 2)
# Apply novel `median-midpoint-classifier' to training data
n = dim(mydata)[1]
n
yHat = matrix(0, nrow = n)
yHat
yHat[mydata$x1 < threshold] = 1
yHat
# Compute accuracy
mean(yHat == mydata$y)
yHat == mydata
yHat == mydata$y
yHat == mydata$y
yHat == mydata$y
yHat == mydata
# Identify indices of k nearest neighbours
which(distances <= sorted_distances[k])
xStar = c(0.5, 1)
n = dim(mydata)[1]
k = 10
X = model.matrix(y ~ 0 + ., data=mydata)
# Initiatlize distance vector
distances = matrix(0, ncol = n)
# Use for() loop to fill in distances
for(i in 1:n){
distances[i] = euclidean_distance(xStar, X[i,])
}
# Sort distances (smallest to largest by default)
sorted_distances = sort(distances)
euclidean_distance = function(X, Y){
# Euclidean distance between two
# equal-length vectors, X and Y
# Input:
#   X: vector
#   Y: vector
# Output:
#   distance between X and Y
return(sqrt(sum((X - Y)^2)))
}
# test function
euclidean_distance(c(0, 0), c(3, 4))
xStar = c(0.5, 1)
n = dim(mydata)[1]
k = 10
X = model.matrix(y ~ 0 + ., data=mydata)
# Initiatlize distance vector
distances = matrix(0, ncol = n)
# Use for() loop to fill in distances
for(i in 1:n){
distances[i] = euclidean_distance(xStar, X[i,])
}
# Sort distances (smallest to largest by default)
sorted_distances = sort(distances)
sorted_distances
# Identify indices of k nearest neighbours
which(distances <= sorted_distances[k])
# Look at corresponding y values
mydata$y[which(distances <= sorted_distances[k])]
# Look at corresponding y values
mydata$y[which(distances <= sorted_distances[k])]
# Check which is the majority
# if average > 0.5, then predict y = 1, otherwise, y = 0
mean(mydata$y[which(distances <= sorted_distances[k])])
# Take the above, and put it into a function
kNN = function(xStar, y, X, k){
# Inputs:
#   xStar: input vector to be classified
#   y: 0/1 training outputs
#   X: training inputs in matrix form
#   k: positive integer, number of neighbours
# Outputs:
#   yHat: 0/1 predicted output
n = dim(X)[1]
distances = matrix(0, ncol = n)
for(i in 1:n){
distances[i] = euclidean_distance(xStar, X[i,])
}
sorted_distances = sort(distances)
if(mean(y[which(distances <= sorted_distances[k])]) > 0.5){
yHat = 1
}else{
yHat = 0
}
return(yHat)
}
# test function
kNN(xStar, mydata$y, X, 10)
n = dim(mydata)[1]
X = model.matrix(y ~ 0 + ., data=mydata)
yHat = matrix(0, ncol = n)
k = 10
# Predict y for each training observations
for(i in 1:n){
yHat[i] = kNN(X[i,], mydata$y, X, k)
}
# Compute accuracy
mean(yHat == mydata$y)
### STAT5P87 - Week 2
getwd()
# load the dataset
mydata = read.csv('prostate-data.csv')
# Look at the header
head(mydata)
# load the dataset
mydata = read.csv('prostate-data.csv')
### STAT5P87 - Week 2
getwd()
